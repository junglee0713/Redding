Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	megahit_unpaired
	1

rule megahit_unpaired:
    input: /scr1/users/leej39/Redding/Redding_Cleaned_Data/concatenated_fastq/S13_R1.fastq.gz
    output: /scr1/users/leej39/Redding/assembly/megahit/S13_asm/final.contigs.fa
    jobid: 0
    wildcards: sample=S13


        megahit -r /scr1/users/leej39/Redding/Redding_Cleaned_Data/concatenated_fastq/S13_R1.fastq.gz -o /scr1/users/leej39/Redding/assembly/megahit/S13_asm --continue ||         if [ ! -a /scr1/users/leej39/Redding/assembly/megahit/S13_asm/final.contigs.fa ]; then touch /scr1/users/leej39/Redding/assembly/megahit/S13_asm/final.contigs.fa; fi
        
Finished job 0.
1 of 1 steps (100%) done
Complete log: /scr1/users/leej39/Redding/.snakemake/log/2019-09-03T141722.684260.snakemake.log
